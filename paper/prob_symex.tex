\section{Probabilistic Symbolic Execution}
\label{sec:pse}

Symbolic execution (section~\ref{sec:back:symexe}) produces path conditions (PCs), i.e., constraints on the inputs, that characterise how a certain target property can be reached. During the process of symbolic execution, the most important question to answer about each PC is whether it is satisfiable or not.  If not, then the corresponding path does not need to be analysed any further (see Algorithm~\ref{alg-symexe}).  However, now we are additionally interested in the \emph{probability} of a target property being satisfied. 

For simplicity we assume we are working with a uniform usage profile for the program under analysis.  In other words, all input values are equally likely.  Note that arbitrary usage profiles can be embedded in the code, and hence this assumption is not a restriction on the generality of the approach. {\bf this now needs to link to somewhere where we discuss this}. Another simplifying assumption is that all the input variables range over finite discrete domains; the combined input domain is denoted by $D$~\cite{filieri-etal-icse2013}. Again, this is not a general restriction and we relax this assumption in more recent work~\cite{Borges2014PLDI}.

\mycomment{For Antonio: this discussion moves to your section}
\subsubsection{Computing Probabilities using Model Counting} 
To compute the probabilities of path conditions, we use a quantification procedure for the generated constraints. In~\cite{filieri-etal-icse2013} we use model counting techniques; libraries such as LattE~\cite{deLoera-etal-2012}, algorithmically calculate the exact number of points inside a bounded (possibly very large) region described by linear constraints over a discrete domain.  In more recent work~\cite{Borges2014PLDI}, we develop quantification procedures for the analysis of programs that have mixed integer and floating point constraints of arbitrary complexity.

To use model counting techniques to compute the probability $\x{Pr}(\x{pc})$ of path condition \x{pc}, we define a counting function, $\sharp(\x{pc})$, that returns the number of elements of $D$ that satisfy $\x{pc}$. Because we assume that $D$ is finite and countable, $\sharp(\cdot)$ always produces a finite non-negative integer, and $\x{Pr}(\x{pc})$ is, by definition~\cite{pestman2009}, $\sharp(\x{pc}) / \sharp(D)$ (where $\sharp(D)$ is the size of the non-empty input domain). 

\subsection{Approach}

To allow for a more general description of the approach to probabilistic symbolic execution we modify Algorithm~\ref{alg-symexe}, to sample and process symbolic paths one at a time. This processing includes the calculation of probabilities as described above.  The modified algorithm (in Algorithms~\ref{alg-pse} and~\ref{alg-symsample}) allows us to better handle the case where only a subset of paths of the program is analysed. The interested reader is referred to \cite{FSE014} for a more detailed discussion of the precise algorithm.

\begin{minipage}{0.4\textwidth}
\begin{algorithm}[H]
\floatname{algorithm}{Alg.}
\caption{{\tt pse}$(l,m,\phi)$}
\label{alg-pse}
\begin{algorithmic}
 \REPEAT
  \STATE $p \gets {\tt symsample}(l_0, m_0, \x{true})$
  \STATE $\x{processPath}(p)$
 \UNTIL {$\x{stoppingSearch}(p)$}
\end{algorithmic}
\end{algorithm}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{algorithm}[H]
\floatname{algorithm}{Alg.}
\caption{{\tt symsample}$(l,m,\phi)$}
\label{alg-symsample}
\begin{algorithmic}
 \IF{$\x{stoppingPath}(\phi)$} 
 \RETURN $\phi$
 \ENDIF
 \WHILE{$\neg branch(l)$}
   \STATE $m \gets m\lrangle{v, e}$
   \STATE $l \gets succ(l)$
 \ENDWHILE
 
 
 \STATE $c \gets \x{cond}(l)(m)$
 
 \IF{$\x{selectBranch}(c,\phi)$}
   \RETURN {\tt symsample}$(\x{succ_t}(l), m, \phi \wedge c)$
 \ELSE
   \RETURN {\tt symsample}$(\x{succ_f}(l), m, \phi \wedge \neg c)$
 \ENDIF
\end{algorithmic}
\end{algorithm}
\end{minipage}

$\newline$

Below we discuss \x{stoppingPath}, \x{selectBranch}, \x{stoppingSearch} and \x{processPath}. At a high level, {\tt symsample} is called from the initial state of the program with $\phi=\mathtt{true}$ as the current path condition;  it returns a single path which is then processed.  This is followed by a check to see if the analysis is complete and can stop. Within {\tt symsample} we first check to see if the search needs to be stopped; otherwise, we symbolically execute the program up to the next branching point and decide which of the next branching statements must be taken. Note that now only one branch is taken, unlike in Algorithm~\ref{alg-symexe} where both branches could be taken if they were both satisfiable. 

\subsubsection{stoppingPath} is the same as in the original symbolic execution algorithm and is there to handle loops conditioned on input variables, since these can cause infinite executions. However, since some paths might now be truncated before reaching its target property, we introduce three types of paths, (1) success paths that reach the target property and the property evaluates to true, (2) failure paths, that reaches the property but the property fails and  (3) grey paths that got truncated before reaching the property. We consider these as three disjoint sets of paths and calculate the cumulative probability of success (i.e., the reliability of the code), failure and grey paths.  Grey paths can be handled optimistically (grouped with the success paths), pessimistically (grouped with the failure paths) or kept separate and be used as a measure for how confident we are in our estimates (for example if the grey paths probability is very low, we are more confident). 

\subsubsection{selectBranch}  In the context of symbolic execution, we define a sample as the
simulation of one symbolic path. Whenever a branch is encountered during such simulation, the decision to proceed along either of the alternative branches has to be taken according to the probability
of satisfying the corresponding branch conditions. To calculate these we calculate the number of solutions for each path condition as described at the beginning of this section. at each branching point we therefore have the count for the PC that reached the branching point ($\sharp(\phi)$) and the counts for the path condition for both branches ($\sharp(\phi \wedge c)$ and $\sharp(\phi \wedge \neg c)$). The probability for the true branch is thus $Pr(\x{succ_t}(l)) = \sharp(\phi \wedge c)/\sharp(\phi)$ and for the false branch it is $Pr(\x{succ_f}(l)) = \sharp(\phi \wedge \neg c)/\sharp(\phi)$.  

%Note that it might seem excessive to calculate these probabilities, to enable sampling, but fortunately they are also required for the probabilistic analysis in general, discussed next.

%\begin{itemize}
%\item If we sample exhaustively then we could pick branches any which way we want to, but we have to record which ones we have picked to allow termination [ note we will explain this in the processPath section this requires us to explain the counting and subtracting values etc.
%\item to do a proper monte carlo simulation we need to consider the counts of each branch
%\item could be elaborate here and use heuristics
%\item what if the branch is nondeterministic?
%\end{itemize}

\subsubsection{processPath} calculates the probability for the path being processed and checks whether the path falls into the success, failure or grey set. Note that many of these calculations have already been preformed during the {\tt selectBranch} and caching is used to eliminate duplication. 

In addition to the probability calculations, another import task performed here is to handle sampling without replacement. More specifically, how to ensure an exhaustive analysis can be done even when certain behaviours have very small probability (and thus would be hard to sample in a purely Monte Carlo fashion). We leverage the counts we store for each path condition to ensure no path is sampled twice (when we don't want replacement). Whenever a path is finished being explored, we subtract the final PC's count from all the PC counts along the current path back to the root. Note these counts are being used by \x{selectBranch} to calculate the conditional probabilities at a branch, and thus it changes the distribution of the probabilities. More importantly, if a count becomes zero it will never be sampled. As more of the paths of the program is analysed zero are being propagated up the tree until the root node's count becomes zero at which point all paths have been explored. 

\subsubsection{stoppingSearch} uses either a measure of confidence based on the percentage of the input domain that has been explored, or, a statistical measure of confidence. 

Enough confidence exist about the portion of the input domain that has been analysed when  $1 - Pr(\x{success}) + Pr(\x{failure}) < \epsilon$.  If we treat grey paths separately this means $Pr(\x{grey}) < \epsilon$. Where $\epsilon$ is provided by the user, and is typically very small. Note that although it is shown that \x{stoppingSearch} takes the path as input, in reality it just reuses the results computed during the \x{processPath}. 

\mycomment{Corina: Antonio can you help out with the statistical portion}



%\begin{itemize}
%\item now we have to consider the domain coverage, i.e. stopping when we have searched a pre-%defined level of the domain, this needs to include the discussion about gray paths
%\item also need to talk about the statistical approach from FSE paper, hopefully Antonio can do this, the SA contingent is not capable!
%\item need to mention sample with replacement here as well
%\end{itemize}

\subsection{Handling nondeterminism}

Handling nondeterminism within the systems being analysed has been studied in \cite{Filieri2013} in the context of scheduling choices in concurrent programs. The approach was to determine the schedule giving the highest (or lowest) reliability. More recently an approach based on value iteration learning was presented in \cite{Luckow2014} to handle the problem in a more general fashion.

\subsection{More and varied probabilistic symbolic execution}

\subsubsection{Brief History}
Probabilistic symbolic execution was introduced in \cite{Geldenhuys2012} where the approach was to do model counting (using LattE) on-the-fly during symbolic execution (as in Algorithm~\ref{alg-symexe}). This work was extended in \cite{Filieri2013} to collect path conditions from symbolic execution and then calculate the reliability of the code. This work also showed how usage profiles can be handled. In both these works it is important to observe that all paths of the program is analysed and thus the probability calculations are precise. 

The work in \cite{Sankaranarayanan2013} was the first to apply sampling of paths during static analysis to provide a probability calculation with a certain confidence. They applied the approach to calculate bounds on the probability of assertions holding in the code. In \cite{Filieri2014} an approach similar to Algorithm~\ref{alg-pse} was used to also sample paths and then use Bayesian estimation and hypothesis testing. This paper also introduced the subtraction of the counts to ensure rare events can be sampled (see {\tt processPath above}). 


\mycomment{Anto: the next paragraph will be updated after completing sect 3}
Another important dimension to consider is how to count the solutions for constraints in various domains. The work so far described has mostly focussed on linear integer arithmetic, since the theory is decidable and thus often used as the basis for symbolic execution tools. Fortunately, as already mentioned, efficient model counters also exist for this domain (such as LattE\cite{} and Barvinok\cite{}). In \cite{Borges2014} non-linear and bounded floating-point domains are handled giving accurate estimates of the size of the solution space. Counting the solutions to constraints complex data-structures, such as objects in Java, are addressed in \cite{Filieri2015}. New domains such counting the solutions to string domains \cite{Aydin2015} and the more general all solutions to a SAT formula (\#SAT) \cite{Chakraborty2014} has recently been proposed. 

\subsubsection{Future Directions}

There are many applications for probabilistic symbolic execution, but most work so far has focussed just on the probability of failure/success of a program under varying input distributions; i.e. the focus has mainly been on reliability. 

Program understanding has been touched on in \cite{Geldenhuys2012} and \cite{Filieri2015} where errors are found by observing unexpected probabilities for certain behaviours. This area should be studied more and useful visualisations for probabilities should be investigated. 

Probabilistic symbolic execution is particularly well suited for quantifying the difference between two versions of a program~\cite{Filieri2015b}. This makes it an ideal approach to rank how close a program is to a given oracle program, which has applications in mutation analysis, program repair, approximate computing or even in marking student assignments. 

Probabilistic programming is becoming very popular \cite{Gordon2014}, but the current approaches mainly focus on sampling, whereas a more accurate approach would be to use probabilistic symbolic execution. 



 
