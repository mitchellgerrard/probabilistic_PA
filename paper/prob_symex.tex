\subsection{Probabilistic Symbolic Execution}
\label{sec:pse}

Symbolic execution produces path conditions (PCs), i.e., constraints on the inputs, that characterize how a certain target property can be reached. During the process of symbolic execution, the most important question to answer about each PC is whether it is satisfiable or not.  If not, then the corresponding path does not need to be analyzed any further.  However, now we are additionally interested in the \emph{probability} of a target property being satisfied. 

For simplicity, we assume we are working with a uniform usage profile for the program under analysis.  In other words, all input values are equally likely.  
See \cite{Filieri2013} for a detailed discussion of usage profiles within symbolic execution.
\ignore{
Note that arbitrary usage profiles can be embedded in the code, and hence this assumption is not a restriction on the generality of the approach. 
}

For example, in Figure~\ref{fig:symex:illus}, 
we introduce variables $b_0$ and $b_1$ to model 
the two {\tt drawBernoulli} distributions from Figure~\ref{fig:example};
the domains of those variables consists of 10 values and the tests
check for half of the domain, which corresponds to the 0.5 parameter
in the Bernoulli distribution.
Note that this program now has 3 inputs and an input domain size of
$10 \times 10 \times 100 = 10000$.
\ignore{
As in Section~\ref{sec:computingprobabilitiesExact}, $D$ represents the finite discrete domain of the variables.
}
The domain of variables, which is finite and discrete, is denoted by $D$.

\begin{figure}[t]
\begin{minipage}{0.3\textwidth}
\begin{algorithmic}
  \STATE $\triangleright\quad b_0,b_1\in\{0,\ldots,9\}$
  \IF{$b_0<5$}
    \IF{$b_1<5$}
      \IF{$x\le60$}
        \STATE $\ldots A$
      \ELSE
        \STATE \textbf{assert} \FALSE
      \ENDIF
    \ELSE
      \IF{$x\le30$}
        \STATE $\ldots B$
      \ELSE
        \STATE \textbf{assert} \FALSE
      \ENDIF
    \ENDIF
  \ELSE
    \IF{$x\le55$}
      \STATE $\ldots C$
    \ELSE
      \STATE \textbf{assert} \FALSE
    \ENDIF
  \ENDIF
\end{algorithmic}
\end{minipage}
\begin{minipage}{0.6\textwidth}
\def\llabel#1{\makebox(0,0)[r]{\small\strut#1\space}}
\def\rlabel#1{\makebox(0,0)[l]{\small\strut\space#1}}
\def\nlabel#1{\begin{picture}(0,0)%
  \put(0,0){\circle{10}}\put(0,0){\makebox(0,0){\small#1}}\end{picture}}
\def\mlabel#1{\begin{picture}(0,0)%
  \put(0,0){\circle{14}}\put(0,0){\makebox(0,0){\small#1}}\end{picture}}
\begin{picture}(250,260)%\put(0,0){\framebox(250,260){}}%
  \put(140,240){\begin{picture}(0,0)
    \put(0,0){\nlabel{1}}
    \put(-3.00,-4.00){\line(-3,-4){54.00}}
    \put(-15,-20){\llabel{$b_0<5$}}
    \put(-25,-32){\llabel{$5000$}}
    \put(-60,-80){\begin{picture}(0,0)
      \put(0,0){\nlabel{2}}
      \put(-2.24,-4.47){\line(-1,-2){35.53}}
      \put(-10,-20){\llabel{$b_1<5$}}
      \put(-17,-32){\llabel{$2500$}}
      \put(-40,-80){\begin{picture}(0,0)
        \put(0,0){\nlabel{3}}
        \put(-1.21,-4.85){\line(-1,-4){17.09}}
        \put(-5,-20){\llabel{$x\le60$}}
        \put(-7,-32){\llabel{$1500$}}
        \put(-20,-80){\mlabel{$A$}}
        \put(1.21,-4.85){\line(1,-4){17.09}}
        \put(5,-20){\rlabel{$x>60$}}
        \put(7,-32){\rlabel{$1000$}}
        \put(20,-80){\mlabel{$A'$}}
        \end{picture}}
      \put(2.24,-4.47){\line(1,-2){35.53}}
      \put(10,-20){\rlabel{$b_1\ge5$}}
      \put(17,-32){\rlabel{$2500$}}
      \put(40,-80){\begin{picture}(0,0)
        \put(0,0){\nlabel{4}}
        \put(-1.21,-4.85){\line(-1,-4){17.09}}
        \put(-7,-30){\llabel{$x\le30$}}
        \put(-9,-42){\llabel{$750$}}
        \put(-20,-80){\mlabel{$B$}}
        \put(1.21,-4.85){\line(1,-4){17.09}}
        \put(7,-30){\rlabel{$x>30$}}
        \put(9,-42){\rlabel{$1750$}}
        \put(20,-80){\mlabel{$B'$}}
        \end{picture}}
      \end{picture}}
    \put(3.00,-4.00){\line(3,-4){54.00}}
    \put(15,-20){\rlabel{$b_0\ge5$}}
    \put(25,-32){\rlabel{$5000$}}
    \put(60,-80){\begin{picture}(0,0)
      \put(0,0){\nlabel{5}}
      \put(-1.21,-4.85){\line(-1,-4){17.09}}
      \put(-5,-20){\llabel{$x\le55$}}
      \put(-12,-32){\llabel{$2750$}}
      \put(-20,-80){\mlabel{$C$}}
      \put(1.21,-4.85){\line(1,-4){17.09}}
      \put(5,-20){\rlabel{$x>55$}}
      \put(12,-32){\rlabel{$2250$}}
      \put(20,-80){\mlabel{$C'$}}
      \end{picture}}
    \end{picture}}
\end{picture}
\end{minipage}
\caption{Illustration of symbolic execution}
\label{fig:symex:illus}
\end{figure}

%To compute the probabilities of path conditions, we use a quantification procedure for the generated constraints. In~\cite{filieri2013reliability} we use model counting techniques; libraries such as LattE~\cite{deloera2012software}, algorithmically calculate the exact number of points inside a bounded (possibly very large) region described by linear constraints over a discrete domain.  In more recent work~\cite{borges2014compositional}, we develop quantification procedures for the analysis of programs that have mixed integer and floating point constraints of arbitrary complexity.

%To use model counting techniques to compute the probability $\x{Pr}(\x{pc})$ of path condition \x{pc}, we define a counting function, $\sharp(\x{pc})$, that returns the number of elements of $D$ that satisfy $\x{pc}$. Because we assume that $D$ is finite and countable, $\sharp(\cdot)$ always produces a finite non-negative integer, and $\x{Pr}(\x{pc})$ is, by definition~\cite{pestman1998mathematical}, $\sharp(\x{pc}) / \sharp(D)$ (where $\sharp(D)$ is the size of the non-empty input domain). 

\subsubsection{Approach}

We outline a general approach to probabilistic symbolic execution
that accomodates many of the advances in the recent literature.
Algorithms~\ref{alg-pse} and~\ref{alg-symsample} are modifications of
the traditional symbolic execution algorithm to sample and process 
symbolic paths one at a time. 
This processing includes the calculation of probabilities as described in
the next section.
The interested reader is referred to \cite{filieri2014statistical} for a more detailed discussion of the precise algorithm.

When considering the example in Figure~\ref{fig:symex:illus}, each of the six paths from the root to the leaves can be sampled and the path condition describing that path will be the conjunct of the constraints along the path; for example the leftmost path will have $b_0 < 5 \wedge b_1 < 5 \wedge x \le 60$ as its path condition. 

Below we discuss \x{stoppingPath}, \x{selectBranch}, \x{stoppingSearch} and \x{processPath} of Algorithms~\ref{alg-pse} and~\ref{alg-symsample}. At a high level, {\tt symsample} is called from the initial state of the program with $pc=\mathtt{true}$ as the current path condition;  it returns a single path which is then processed.  This is followed by a check to see if the analysis is complete and can stop. Within {\tt symsample} we first check to see if the search needs to be stopped; otherwise, we symbolically execute the program up to the next branching point and decide which of the next branching statements must be taken. Note that now only one branch is taken, unlike in traditional symbolic execution, where both branches could be taken if they were both satisfiable. 

\begin{minipage}{0.4\textwidth}
\begin{algorithm}[H]
\floatname{algorithm}{Alg.}
\caption{{\tt pse}$(l,m,pc)$}
\label{alg-pse}
\begin{algorithmic}
 \REPEAT
  \STATE $p \gets {\tt symsample}(l_0, m_0, \x{true})$
  \STATE $\x{processPath}(p)$
 \UNTIL {$\x{stoppingSearch}(p)$}
\end{algorithmic}
\end{algorithm}
\end{minipage}
\begin{minipage}{0.55\textwidth}
\begin{algorithm}[H]
\floatname{algorithm}{Alg.}
\caption{{\tt symsample}$(l,m,pc)$}
\label{alg-symsample}
\begin{algorithmic}
 \IF{$\x{stoppingPath}(pc)$} 
 \RETURN $pc$
 \ENDIF
 \WHILE{$\neg branch(l)$}
   \STATE $m \gets op(l)(m)$
   \STATE $l \gets succ(l)$
   \STATE $check(l,m,\phi)$
 \ENDWHILE
 
 
 \STATE $c \gets \x{cond}(l)(m)$
 
 \IF{$\x{selectBranch}(c,pc)$}
   \RETURN {\tt symsample}$(\x{succ_t}(l), m, pc \wedge c)$
 \ELSE
   \RETURN {\tt symsample}$(\x{succ_f}(l), m, pc \wedge \neg c)$
 \ENDIF
\end{algorithmic}
\end{algorithm}
\end{minipage}

$\newline$

\paragraph{stoppingPath} is the same as in the original symbolic execution algorithm and is there to handle loops conditioned on input variables, since these can cause infinite executions. However, since some paths might now be truncated before reaching the target property, we introduce three types of paths, (1) success paths, which reach and satisfy the target property, (2) failure paths, which reaches and falsify the property, and (3) grey paths, which are truncated before reaching the property. We consider these as three disjoint sets of paths and calculate the cumulative probability of success (i.e., the reliability of the code), failure and grey paths.  Grey paths can be handled optimistically (grouped with the success paths), pessimistically (grouped with the failure paths) or kept separate and be used as a measure for how confident we are in our estimates (for example, if the grey paths probability is very low, we are more confident). 

\paragraph{selectBranch}  In the context of symbolic execution, we define a sample as the
simulation of one symbolic path. Whenever a branch is encountered during such simulation, the decision to proceed along either of the alternative branches has to be taken according to the probability
of satisfying the corresponding branch conditions. To calculate these, we calculate the number of solutions for each path condition as described at the beginning of this section---techniques for calculating this number are detailed in
Section~\ref{sec:computingprobabilities}.

At each branching point, we have the count for the PC that reached the branching point ($\sharp(pc)$) and the counts for the path condition for both branches ($\sharp(pc \wedge c)$ and $\sharp(pc \wedge \neg c)$). The probability for the true branch is thus $Pr(\x{succ_t}(l)) = \sharp(pc \wedge c)/\sharp(pc)$ and for the false branch it is $Pr(\x{succ_f}(l)) = \sharp(pc \wedge \neg c)/\sharp(pc)$.  

In the example of Figure~\ref{fig:symex:illus}, when we sample at node $3$, we have that the path condition at the node is $pc = b_0 < 5 \wedge b_1 < 5$ and $\sharp(pc) = 2500$. The true branch ($b_0 < 5 \wedge b_1 < 5 \wedge x \le 60$ with a count of $1500$) will thus be taken with probability $1500/2500 = 0.6$ and the false branch will be taken with probability $0.4$.  

\paragraph{processPath} calculates the probability for the path being processed and checks whether the path falls into the success, failure or grey set. Note that many of these calculations have already been performed during the {\tt selectBranch}, and caching is used to eliminate duplication. 

Again in the example of Figure~\ref{fig:symex:illus}, the paths ending at the labels $A', B'$ and $C'$ indicate assertion failures, and thus the probability of failure will be $1500/10000 + 1750/10000 + 2250/10000 = 0.55$.  Since there are no loops in the example the rest of the paths indicate success, which will have probability $0.45$.

In addition to the probability calculations, another important task performed here is to handle sampling without replacement. More specifically, how to ensure an exhaustive analysis can be done even when certain behaviors have very small probability (and thus would be hard to sample in a purely Monte Carlo fashion). We leverage the counts we store for each path condition to ensure no path is sampled twice (when we don't want replacement). Whenever a path is finished being explored, we subtract the final PC's count from all the PC counts along the current path back to the root. Note that these counts are being used by \x{selectBranch} to calculate the conditional probabilities at a branch, and thus it changes the distribution of the probabilities. More importantly, if a count becomes zero, it will never be sampled. The more paths of the program are analyzed, 
the more counts propagate up the tree until the root node's count becomes zero, at which point all paths have been explored. 

\paragraph{stoppingSearch} uses either a measure of confidence based on the percentage of the input domain that has been explored, or it uses a statistical measure of confidence. 

Enough confidence exists about the portion of the input domain that has been analyzed when  $1 - Pr(\x{success}) + Pr(\x{failure}) < \epsilon$.  If we treat grey paths separately, this means $Pr(\x{grey}) < \epsilon$. The parameter $\epsilon$ is provided by the user, and is typically very small. Note that although it is shown that \x{stoppingSearch} takes the path as input, in reality it just reuses the results computed during the \x{processPath}. 

\ignore{
\mycomment{Corina: Antonio can you help out with the statistical portion}
}

\subsubsection{Handling nondeterminism}

Handling nondeterminism within the systems being analyzed has been studied in \cite{Filieri2013} in the context of scheduling choices in concurrent programs. The approach was to determine the schedule giving the highest (or lowest) reliability. More recently, an approach based on value iteration learning was presented in \cite{luckow2014exact} to handle the problem in a more general fashion.

\subsubsection{More and varied probabilistic symbolic execution}

Probabilistic symbolic execution was introduced in \cite{Geldenhuys2012}, where the approach was to do model counting (using LattE) on-the-fly during symbolic execution. This work was extended in \cite{Filieri2013} to collect path conditions from symbolic execution and then calculate the reliability of the code. This work also showed how usage profiles can be handled. In both works it is important to observe that {\it all} paths of the program are analyzed, and thus the probability calculations are precise. 

The work in \cite{Sankaranarayanan2013} was the first to apply sampling of paths during static analysis to provide a probability calculation with a certain confidence bound. They applied the approach to calculate bounds on the probability of assertions holding in the code. In \cite{filieri2014statistical}, an approach similar to Algorithm~\ref{alg-pse} was used to also sample paths and then use Bayesian estimation and hypothesis testing. This paper also introduced the subtraction of the counts to ensure rare events can be sampled (see {\tt processPath above}). 

\ignore{
\mycomment{Anto: the next paragraph will be updated after completing sect 3}
Another important dimension to consider is how to count the solutions for constraints in various domains. The work so far described has mostly focussed on linear integer arithmetic, since the theory is decidable and thus often used as the basis for symbolic execution tools. Fortunately, as already mentioned, efficient model counters also exist for this domain (such as LattE\cite{deloera2012software} and Barvinok\cite{verdoolaegesoftware}). In \cite{Borges2014} non-linear and bounded floating-point domains are handled giving accurate estimates of the size of the solution space. Counting the solutions to constraints complex data-structures, such as objects in Java, are addressed in \cite{Filieri2015}. New domains such counting the solutions to string domains \cite{Aydin2015} and the more general all solutions to a SAT formula (\#SAT) \cite{Chakraborty2014} has recently been proposed. 
}

