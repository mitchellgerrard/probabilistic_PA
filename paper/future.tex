\section{Open Questions and Future Directions}
\label{sec:future}

There are many applications for probabilistic program analysis, but most work so far has focussed just on the probability of failure/success of a program under varying input distributions; i.e. the focus has mainly been on reliability.

\begin{enumerate}
\item Program understanding has been touched on in \cite{Geldenhuys2012} and \cite{Filieri2015} where errors are found by observing unexpected probabilities for certain behaviours. This area should be studied more and useful visualisations for probabilities should be investigated.


\item Probabilistic symbolic execution is particularly well suited for quantifying the difference between two versions of a program~\cite{Filieri2015b}. This makes it an ideal approach to rank how close a program is to a given oracle program, which has applications in mutation analysis, program repair, approximate computing or even in marking student assignments.

\item Probabilistic programming is becoming very popular \cite{Gordon2014}, but the current approaches mainly focus on sampling, whereas a more accurate approach would be to use probabilistic symbolic execution.  This requires supporting conditioning, which should be possible since this simply means aborting the path and ignoring its probability mass and then renormalizing the resultant distribution.

\item analysis tools: tools support for prob. data flow analysis is really lacking
\item what kind of support would be useful for specifying input distributions?
the single variable stuff is easy, but what about dependent input variables?
should people think about using probabilistic programs for that?  do we have an example challenge problem?
\item extending counting for other domains: reals, strings, structs, non-linear
\item building a robust and flexible counting tool: that mixes methods, that cancompute prob. estimates with bounds, etc.
\item hybrid approaches: could we identify portions of a state
space that could be analyzed exactly through symex and then fold
that information back into mc/dfa approaches to boost their precision
\item inference: while we don't cover it in this paper, a key feature of
the most recent prob. programming languages is conditioning in the form
of an "observe" statement.  This functions exactly like an "assume" 
statement and could be used to drive backtracking in mc/symex.  Work
would have to be done to renormalize the prob. measures as in existing
approaches.
\item prob dfa and prob symex both seem to need an accurate characterization
of the distributions of "random" libraries, so that those distributions can be 
discretely bounded or approximated.  It might be interesting for a student
to do a comprehensive survey of the distributions generated by common
libraries to see if they really do produce what they say.
\item in data flow analysis we think of boosting precision by using partial
path sensitivity, i.e., enriching the abstract domain to allow for the recording of information related to branch conditions, in some sense this is bringing some path condition like reasoning into the mix.  can this be done with prob. dfa?
\item concurrency for scalability (doesn't Kasper's work already do this?)
\item ... add more here ...
\end{enumerate}
