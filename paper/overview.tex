\subsection{Extending Program Analyses with Probabilities}
\label{sec:overview}

The literature on incorporating probabilistic techniques into 
program analysis is large and growing, technically deep, and quite
varied.  In this paper, our
intention is to expose key similarities and differences between 
families of approaches and, in so doing, provide the reader with
intuitions that are often missing in the detailed presentation of techniques.

\subsubsection{Where do the probabilities come from?}
There are two perspectives adopted in the literature.
Programs are \textit{implicitly} probabilistic because the distributions
from which input values are drawn are not specified in the program,
but are characteristics of the execution environment.
Alternately, programs are \textit{explicitly} probabilistic in 
that the statements
within the program define the input probability distributions.

It is possible to transform explicit probabilistic constructs
by introducing auxiliary input variables and then specifying
their distributions.   For the example, this would result
in the addition of two integer input variables 
\begin{quote}
\texttt{m(int x, int b1, int b2) \{...} 
\end{quote}
where the two instances of
\texttt{drawBernoulli(0.5)} expressions would be replaced
by \texttt{b1} and \texttt{b2}, respectively.  The input
distribution for each auxiliary input would then be specified
as a set of pairs,
$\{ \ldots, (-1,0), (0,0.5), (1,0.5), (1,0), \ldots \}$
where the first component defines a value and the second defines
its probability.

Section~\ref{sec:pdfa} discusses approaches where probabilities
governing specific branch outcomes, as opposed to input values,
are built into the program model from knowledge the developer
has at hand, while Sections~\ref{sec:pse} and \ref{sec:computingprobabilities}
describe techniques for computing such probabilities from information about
the program semantics and input distribution.

\subsubsection{What does the analysis compute?}
There are again two perspectives adopted in the literature.
One can view a probabilistic program as a transformer on probability
distributions; the analysis computes the probability distribution over the
concrete domain which holds at a program state.
Alternatively, one can view a probabilistic program as a program 
whose inputs happen
to vary in some principled way; the analysis computes program 
properties---properties of sets of concrete domain elements---along with a characterization
of how these properties vary with varying input.
Within these approaches, there are different types of approximations
computed for probabilities.  It is common to compute upper bounds
on probabilities for program properties, but lower bounds can 
be computed as well.  In addition, it is possible to estimate the
probability within some margin of error---an approach that several
techniques explore---and it is even possible to compute the probability
\textit{exactly}, if certain restrictions hold on the program and its distributions.

Conceptually, there are two pieces of information that are necessary
to reason probabilisticaly about a set of values: a quantity
that approximates the probability of each value in the set 
and the number of values in the set.  
Early probabilistic static analysis
techniques did not explicitly capture this latter quantity, but
more recent work discussed in Section~\ref{sec:pse}, using the
techniques of Section~\ref{sec:computingprobabilities}, 
does capture this quantity, as do other
recent approaches~\cite{mardziel2013dynamic}.


\subsubsection{Mixing abstraction with probabilities}
Any analysis that hopes to scale will have to approximate
behavior.  As explained earlier, in static analyses it is common
to model such overapproximation using nondeterministic choice.
Across all of the analysis techniques we survey, MDPs
have been used when there is a need to mix probabilistic
and nondeterministic choice.   
An important consequence of using MDPs is that it is no longer possible
to compute a single probabilistic characterization of a property.
Instead, analyses can compute, across the set of all possible sequences
of nondeterministic choice outcomes, the minimal and maximal 
probabilities for a property to hold.
