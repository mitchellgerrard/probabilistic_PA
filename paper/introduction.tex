\section{Introduction}
\label{sec:introduction}

Static program analyses aim to calculate properties of 
the possible executions of a program without ever running the program,
and have been an active topic of study for over five decades.
Initially developed to allow compilers to generate more efficient
output programs, by the mid-1970s \cite{fosdick1976data} researchers had
understood that such program analyses could be applied to fault
detection and verification of the absence of specific classes of faults.

The power of these analysis techniques, and what distinguishes them from
simply running a program and observing its behavior, is their
ability to reason about program behavior without knowing all of the
exact details of program execution (e.g., the specific 
input values provided to the program, the set of operating system
thread scheduler decisions).  This tolerance of uncertainty allows analyses
to provide useful information when users don't know exactly how
a program will be used (e.g., when a program is first released, when
embedded systems read sensor inputs from the physical world, or
when it is ported to an operating system with a different scheduler).

Static analyses model uncertainty in program behavior
through the use of various forms of abstraction and symbolic representation.
For example, symbolic expressions are used to encode logical constraints 
in symbolic execution~\cite{king1976symbolic}, to define abstract domains
in data flow analysis~\cite{kildall1973unified,cousot1977abstract}, and to 
capture sets of data values that constitute reachable states via
predicate abstraction~\cite{graf1997predabs}.
Nondeterministic choice is another widely used approach for modeling
uncertainty---for instance, in modeling uncertain branch 
decisions in data flow analysis,
or scheduler decisions in model checking.
While undeniably effective, these approaches sacrifice potentially
important distinctions in program behavior.   

Consider a program that accepts an integer input representing
a person's income.  A static analysis might reason about the program
by allowing any integer value, or, perhaps, by applying
some simple assumption, i.e., that income must be non-negative.
Domain experts have studied income distributions and find that
incomes vary according to a generalized beta distribution 
\cite{mcdonald1984some,thurow1970analyzing}.  Can this type of information be 
exploited to yield useful analysis results when classic
analyses fail, or to reason about new types of program properties?

\ignore{
For decades, there has been a growing awareness of the value of 
incorporating more precise forms of uncertainty into program behavior.  
The field of randomized algorithms has studied how to incorporate
randomness as an additional program input---as a means of achieving
good average case performance, and consequently, as a defense against
intolerable worst case performance.
Programming such algorithms requires that primitives be available
to draw values from probability distributions, and there are many
languages that provide such primitives, e.g., NetLogo \cite{tisue2004netlogo},
the C++ \texttt{$\mathtt{<random>}$} library, and the GNU Scientific library.
}

Whether information about the distribution of
values is embedded within a program or stated as an input assumption,
the semantics of such probabilistic programs is well-understood---and
has long been studied 
\cite{kozen1981semantics,kozen1983probabilistic,jones1990probabilistic,morgan1996probabilistic}
\setcounter{footnote}{0}
\footnote{In recent
years, the term probabilistic program has been generalized beyond
drawing inputs from probability distributions, which we
consider here, to programs that can condition program behavior---by
rejecting certain program runs---and thereby be viewed as
computations over probability distributions.  We refer the reader to the
recent paper by Gordon, Henzinger, Nori and Rajamani \cite{Gordon2014}
for discussion of the analysis of these more general probabilistic programs.}. 
What has lagged behind is the development of frameworks for 
defining and implementing static analysis techniques for such programs.

What would such analyses have to offer?
They can, of course, provide a means of analyzing programs that compute
with values chosen from probability distributions, but they offer much
more.
For example, researchers have explored the use of probabilistic analysis
results to assess the security of software components~\cite{mardziel2013dynamic},
to assess program reliability~\cite{Filieri2013}, to measure program
similarity~\cite{Geldenhuys2012}, 
to characterize the coverage
achieved by an analysis technique~\cite{DwyerASE11}, and to provide information
about program properties when a classic analysis would fail, e.g.,
by running out of memory, time, or due to excessive approximation.

In this paper, we survey work on adapting data flow analysis 
and symbolic execution to use probabilistic information.
We begin with background that provides basic definitions
related to static analysis and probabilistic models.
Section~\ref{sec:overview} attempts to expose some of the key
intuitions and concepts that cross-cut the work in this area.
The following two sections, \ref{sec:pdfa}-\ref{sec:pse}, 
survey work on probabilistic data flow analysis and probabilistic
symbolic execution.  
Section~\ref{sec:computingprobabilities} discusses approaches that
have been developed to reason about the probability of program-related 
events, e.g., executing a path, taking a branch, or reaching a state.
We conclude with a set of open questions
and research challenges that we believe are worth pursuing.

